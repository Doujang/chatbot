# 对话式编程

[//]: # (@stageName conversation_programing)

```对话式编程```是作者 2015年想要开发对话系统的最初动机之一。
目标是可以用多轮对话教会机器人多轮对话，进一步可以教机器人各种能力。

[//]: # (@info)

一言以蔽之，用对话来实现对机器人新能力的编程。

[//]: # (@info)

需要强调的是，"对话式编程" 完全不是 "自然语言编程"，
它的目标不是用自然语言语法取代高度规范化的编程语言，
而是用 "对话" 这种 "交互形式" 实现 "互动式编程"。
关键在于让机器人学会新的能力。


[//]: # (@askChoose)
[//]: # (@routeToRelation children)


## 什么是互动式编程

[//]: # (@stageName interactive_programing)

对于专业程序员而言，编程主要是一次性书写完整的代码，然后通过单元测试、debug调试或部署测试来确保质量。
过程中程序员不会和解释器进行交互，通常和 IDE 提供的查询、提示功能进行交互。

[//]: # (@info)

非专业编程中的互动体验反而多一些，比如给运营人员准备的拖拽式编程，给儿童准备的选择题式编程等。
总得来说，交互式编程不是程序员的单方面输出，解释器具备自我描述、自我展示的能力，能与程序员进行信息交换，提供对代码高级封装后给出来的选择。

[//]: # (@break)

基于图形界面的交互式编程，对于人类接受信息的成本很低，但开发和交互的成本很高。
自然语言是我们人类对外输出信息最为高效的方式。

[//]: # (@info)

当未来我们每个人，上至老人下至小孩，对交互式编程习以为常的时候，一定是以自然语言为主体的。

[//]: # (@askChoose)
[//]: # (@routeToRelation brothers)
[//]: # (@routeToRelation parent b|返回)


## 对话式编程的核心技术

[//]: # (@stageName conversational_programing_core)

我个人认为，自然语言技术对于对话式编程是必要而非充分条件。
工程才是最关键的，需要有```严谨的复杂多轮对话管理```，和```双层解释器的架构```。

[//]: # (@info)

而最本质的一点在于，它必须达到通过自身创造出来的逻辑能力，自身立刻加载。
从而在生产效率上，可以通过反复自我封装，达到指数性质的飞跃。
这也是对话式编程和```图形拖拽编程```的本质区别，后者修改的是别的程序的逻辑，而非自身。

[//]: # (@askChoose)
[//]: # (@routeToRelation children)
[//]: # (@routeToRelation parent b|返回)


### 复杂严谨的多轮对话管理

[//]: # (@stageName complex_dialog_manage)

"复杂而严谨" 的多轮对话管理，指的是没有轮数或语料的限制，上下文之间的跳转和回归有丰富的多样性，同时又是非常规则、可预期的。这一点在 "半开放域对话交互系统" 的话题中有详细的讨论。

[//]: # (@info)

就像我们程序员使用 IDE 一样，我们在任何一个界面时所有可做的事情，构成了一个有限指令的封闭域。
而我们的操作会打开各种 "交互" 界面如菜单、对话框、选择、搜索等等。

[//]: # (@info)

当我们下达一个明确的指令比如切换窗口，执行重构，运行测试等；
所有的后续流程、界面变化、信息呈现、场景切换、回归都必须严格符合预期。
不能是一个概率性的结果。

[//]: # (@askChoose)
[//]: # (@routeToRelation brothers)
[//]: # (@routeToRelation parent b|返回)

### 双层解释器架构

[//]: # (@stageName double_explainer)

我个人设计的方案，认为对话式编程需要同时运行两种类似 "解释器" 的模块。

[//]: # (@info)

第一层是对话层解释器，能够把对话中产生的运行逻辑编辑成逻辑树，保存下来。
这一层还需要具备自我描述、解释和提示的功能。

[//]: # (@break)

第二层则是机器人自己的驱动层，它会动态加载预定义的逻辑树，同时实时加载新改动的内容；
通过这一层来驱动自己的行为。

[//]: # (@info)

所以对话式编程一定会有先针对驱动层的元对话编程，然后才能通过对话的形式生产新的逻辑。
它会是在高级编程语言基础上的更高级语言，才能具备交互编程的能力。

[//]: # (@info)

这也是 "对话" 的优势所在，对话新产生的逻辑对话系统能够立刻执行。
这是图形界面暂时难以达到的，难以想象用图形编辑器拖拽出一个图形编辑器的新功能来。
因为程序生产图形的成本，数百倍于文字。

[//]: # (@askNext)
[//]: # (@routeToRelation parent b|返回)

## 对话式编程的四阶段演进

[//]: # (@stageName conversational_coding_evalution)

我个人设想，对话式编程是一个正在发生中的历史，已经有很多初级形式存在。而它的演进过程可能分为四个阶段。

- 复杂交互管理
- 预定义元对话
- 图灵完备
- 高级封装


[//]: # (@askChoose)
[//]: # (@routeToRelation children)
[//]: # (@routeToRelation parent b|返回)

### 第一阶段，复杂交互管理

[//]: # (@stageName complext_interactive)

要形成双层解释器的架构，并且能实现通用的交互模型。
例如现在的图形界面拖拽编程，就是建立在成熟的```图形界面交互系统```基础上。

[//]: # (@info)

复杂的交互模型，必须是不限轮次、不依赖资源、上下文跳转严谨的。
在此基础上，还必须进一步实现```并行、异步、阻塞```等各种常见的交互特性。


[//]: # (@askNext)
[//]: # (@routeToRelation parent b|返回)

### 第二阶段，预定义的元对话

[//]: # (@stageName meta_dialog)

第二个阶段, 所有早期的交互编程模型，一定是经过严谨设计的固定模型。
比如图形化的拖拽编程界面。

[//]: # (@info)

这个阶段的对话编程系统，可以通过预定义的 "元对话"，生产出新的对话逻辑来。
例如 CommuneChatbot 施工中的一个 Demo，允许用户在对话中制造一个对话式迷宫，一边创造一边调试。

[//]: # (@askNext)
[//]: # (@routeToRelation parent b|返回)


### 第三个阶段，图灵完备阶段

[//]: # (@stageName turing_complete)

对话系统把元对话的层次逐步下探，直到最小的单元，达到编程语言图灵完备的要求。
当然，这个阶段主要需要自然语言理解技术的进步，才能够实现低成本的最小单元表达。

[//]: # (@info)

到这个阶段，意味着第一层对话式的解释器，已经能够编写出第二层驱动器所能实现的一切逻辑。

[//]: # (@info)

这时就正式达到了 "更高级编程语言" 的水平了。实现了 ```二进制编程 -> 语义化编程 -> 跨平台的语义化编程 -> 非编译语言 -> 碎片化语言 -> 碎片化自然语言```  的演进。

[//]: # (@askNext)
[//]: # (@routeToRelation parent b|返回)

### 第四个阶段，高级封装

[//]: # (@stageName advanced_packages)

在底层元对话图灵完备的基础之上，第四个阶段的任务又重新回到第二个阶段。
去封装高级的 "元对话"，来指数级地降低对话式编程的工作量和复杂度。

[//]: # (@info)

到这个阶段，类似《钢铁侠》中斯塔克与人工智能机器人对话，教会它新的任务和命令，就自然可以实现了。


[//]: # (@askNext)
[//]: # (@routeToRelation parent b|返回)

## CommuneChatbot 的探索

[//]: # (@stageName conversational_coding_in_commune)

CommuneChatbot 项目在初步地探索对话式编程的第一阶段和第二阶段。

[//]: # (@info)

v0.1 版旨在开发一个上下文严谨的对话管理内核。
v0.2 版做了优化，形成了一套拥有 depend/yield/block/sleep/gc/backtrace/callback/cancel 等特性的上下文栈结构。以保障各种情形下的上下文切换和回归严格符合预期。

[//]: # (@info)

进一步的，v0.2 实现了四种非阻塞对话机制，包括双工推送、异步非阻塞、多进程对话、同步非阻塞等。
试图实现接近 app、网页应用的复杂交互能力。

[//]: # (@break)

v0.2 版还做了颠覆性的重构，在多轮对话管理逻辑层上搭建了一个配置层，机器人通过读取配置来驱动自己的行为。
从而可以在预定义的元对话中，生产新的对话逻辑配置。然后立刻动态加载，让机器人学会新的能力。

[//]: # (@info)

这相对初级地实现了双层解释器的思路。
而现阶段预定义的元对话，主要用来管理机器人自身的能力，包括用对话教会它新的回复策略，和管理它自身的功能模块。

[//]: # (@break)

开发时设计了好几套元对话能力，包括：

- 创造树状多轮对话的元对话，可以用它来生产文字对话游戏，对话式迷宫等。
- 通过对话生成的问卷调查
- 通过对话生成的 API 调用

[//]: # (@info)

不过元对话需要大量的开发和调试。等我进一步解决了用户乱输入敏感内容的风险后……会把这个模块放出来，作为用户可分享的功能。

[//]: # (@askChoose)
[//]: # (@routeToStage ending)
[//]: # (@routeToRelation parent b|返回)

# 结束

[//]: # (@stageName ending)
[//]: # (@goFulfill)